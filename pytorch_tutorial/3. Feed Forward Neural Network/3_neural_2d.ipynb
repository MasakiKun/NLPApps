{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network with 2D Data (2-dimensional)\n",
    "- Neural Network with 4 layers\n",
    "- 2D data f(x,y) -> R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable\n",
    "from visdom import Visdom\n",
    "viz = Visdom()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/NLPApps/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
      "  after removing the cwd from sys.path.\n",
      "/anaconda3/envs/NLPApps/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
      "  \"\"\"\n",
      "/anaconda3/envs/NLPApps/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  \n",
      "/anaconda3/envs/NLPApps/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "num_data=1000\n",
    "num_epoch=10000\n",
    "\n",
    "x = init.uniform(torch.Tensor(num_data,1),-10,10)\n",
    "y = init.uniform(torch.Tensor(num_data,1),-10,10)\n",
    "z = x**2 + y**2\n",
    "\n",
    "x_noise = x + init.normal(torch.FloatTensor(num_data,1),std=0.5)\n",
    "y_noise = y + init.normal(torch.FloatTensor(num_data,1),std=0.5)\n",
    "z_noise = x_noise**2 + y_noise**2\n",
    "\n",
    "data_noise = torch.cat([x,y,z_noise],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data visualization\n",
    "\n",
    "win_1=viz.scatter(\n",
    "        X=data_noise,\n",
    "        opts=dict(\n",
    "            markersize=5,\n",
    "            markercolor=np.ndarray(shape=[num_data,3],dtype=float,buffer=[51,153,255]*np.ones(shape=[num_data,3]))\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Linear(2,20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20,10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10,5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5,5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5,1),\n",
    "        )\n",
    "\n",
    "loss_func = nn.L1Loss()\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(67.7813, grad_fn=<L1LossBackward>)\n",
      "tensor(67.6264, grad_fn=<L1LossBackward>)\n",
      "tensor(67.4812, grad_fn=<L1LossBackward>)\n",
      "tensor(67.3476, grad_fn=<L1LossBackward>)\n",
      "tensor(67.2176, grad_fn=<L1LossBackward>)\n",
      "tensor(67.0842, grad_fn=<L1LossBackward>)\n",
      "tensor(66.9398, grad_fn=<L1LossBackward>)\n",
      "tensor(66.7739, grad_fn=<L1LossBackward>)\n",
      "tensor(66.5643, grad_fn=<L1LossBackward>)\n",
      "tensor(66.2609, grad_fn=<L1LossBackward>)\n"
     ]
    }
   ],
   "source": [
    "input_data = torch.cat([x,y],1)\n",
    "label = z_noise\n",
    "loss_arr =[]\n",
    "\n",
    "for i in range(num_epoch):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(input_data)\n",
    "    loss = loss_func(output,label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    loss_arr.append(loss.item())\n",
    "    \n",
    "    if i % 100 == 0 and i <1000:\n",
    "        print(loss)\n",
    "        data = torch.cat([input_data.cpu(),output.cpu().data],1)\n",
    "\n",
    "        win_2 =viz.scatter(\n",
    "                X=data,\n",
    "                opts=dict(\n",
    "                markersize=5,\n",
    "                markercolor=np.ndarray(shape=[num_data,3],dtype=float,buffer=128*np.ones(shape=[num_data,3]))\n",
    "            )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-2.1829e-01,  6.2906e-01],\n",
      "        [ 4.4019e-02,  2.7839e-01],\n",
      "        [ 7.0545e-02, -3.8321e-01],\n",
      "        [ 2.1462e-01, -6.5768e-01],\n",
      "        [-5.7392e-01,  5.3798e-01],\n",
      "        [-7.0164e-02,  3.9713e-01],\n",
      "        [ 3.4280e-01, -5.7001e-01],\n",
      "        [ 4.5575e-01,  2.7802e-02],\n",
      "        [ 6.7898e-02,  3.0312e-01],\n",
      "        [ 6.9606e-01, -4.4274e-01],\n",
      "        [-9.5658e-02, -4.1020e-01],\n",
      "        [ 7.6975e-02, -2.5625e-01],\n",
      "        [ 9.8182e-02,  6.4113e-01],\n",
      "        [-5.3003e-02, -3.8306e-01],\n",
      "        [-3.8189e-01, -7.9867e-01],\n",
      "        [-5.2058e-01, -2.1126e-01],\n",
      "        [ 5.4805e-01,  1.4197e-01],\n",
      "        [ 5.5059e-01,  7.5896e-04],\n",
      "        [ 2.4329e-01, -4.2615e-01],\n",
      "        [-7.2765e-01,  1.6022e-01]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.9871, -0.9557,  0.5582,  0.2595,  0.6021, -0.2125,  0.3507,  0.2556,\n",
      "        -1.2364, -0.6652,  0.8409, -0.9147,  0.0719, -0.0893, -0.5686, -1.0666,\n",
      "        -0.3585, -0.7739, -0.4600, -0.4737], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.1276,  0.2526,  0.0066, -0.1662,  0.1108,  0.0679, -0.1873, -0.1950,\n",
      "         -0.0374, -0.2644,  0.1658,  0.2024, -0.2861,  0.2360,  0.2921,  0.2078,\n",
      "         -0.0665, -0.1565,  0.2334,  0.1172],\n",
      "        [ 0.5115,  0.3294, -0.0955, -0.0808, -0.3762,  0.2212, -0.2592, -0.2887,\n",
      "          0.5200,  0.5682, -0.6599,  0.4028,  0.0935,  0.0941,  0.5113,  0.3934,\n",
      "         -0.0556,  0.4166,  0.2455,  0.3459],\n",
      "        [-0.1628,  0.0339, -0.0711, -0.2161,  0.0387, -0.0947,  0.0331, -0.1088,\n",
      "         -0.1397, -0.0644,  0.0219,  0.0134, -0.0165, -0.0256,  0.0839,  0.1185,\n",
      "          0.0630,  0.0540, -0.0396, -0.1115],\n",
      "        [ 0.4055,  0.3893, -0.3571, -0.2390,  0.3217,  0.3118, -0.1145,  0.2768,\n",
      "          0.2482,  0.2011,  0.0741,  0.1328,  0.1201,  0.0510,  0.1812,  0.0654,\n",
      "          0.4823,  0.3218, -0.0130,  0.2270],\n",
      "        [-0.0412, -0.0442,  0.0501,  0.2548, -0.3993,  0.1748,  0.2706, -0.0996,\n",
      "         -0.1631, -0.1125,  0.0212,  0.1153, -0.1610, -0.0528,  0.4260, -0.0078,\n",
      "         -0.0689,  0.1524,  0.2247, -0.2556],\n",
      "        [ 0.1427,  0.0445,  0.1044, -0.0936,  0.1299,  0.1812,  0.0656,  0.0924,\n",
      "         -0.0665, -0.0580, -0.0879, -0.0983, -0.2331,  0.0670,  0.0199, -0.1052,\n",
      "         -0.0872,  0.1382, -0.1471, -0.2297],\n",
      "        [ 0.2870,  0.1136, -0.0263, -0.0354, -0.1181,  0.1066,  0.3582, -0.0221,\n",
      "          0.3725,  0.3493, -0.1371,  0.1181,  0.3004,  0.1980,  0.1458,  0.2347,\n",
      "          0.3776,  0.2578,  0.0723,  0.1166],\n",
      "        [-0.0875, -0.1307,  0.0559, -0.2251, -0.0456,  0.1116, -0.1509,  0.1755,\n",
      "          0.0842,  0.0157,  0.1412, -0.1484,  0.0379, -0.1163,  0.1604,  0.0268,\n",
      "          0.0117,  0.1589, -0.1414, -0.2082],\n",
      "        [-0.0505, -0.1231,  0.0711, -0.0170, -0.0472, -0.1710, -0.1408, -0.1096,\n",
      "         -0.0074,  0.1118, -0.1317, -0.0041, -0.1180,  0.1043, -0.1920,  0.1587,\n",
      "          0.0392,  0.0840, -0.0010,  0.0179],\n",
      "        [ 0.2789,  0.1971, -0.4433,  0.0398, -0.0352, -0.1219, -0.1415, -0.0369,\n",
      "          0.5642,  0.4428, -0.1752,  0.4753, -0.2279,  0.1693,  0.4123,  0.5033,\n",
      "         -0.0400,  0.2674,  0.2353,  0.3000]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0298, -1.9294,  0.1156, -0.4359, -0.2443, -0.2234, -0.6595,  0.0903,\n",
      "        -0.1624, -1.1421], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0923,  0.4891, -0.2689,  0.3886,  0.3081, -0.1277,  0.1299, -0.0139,\n",
      "          0.0914,  0.2754],\n",
      "        [ 0.6102,  1.8910,  0.0600,  0.9053,  0.5968, -0.0420,  0.7989,  0.1027,\n",
      "         -0.1269,  1.1866],\n",
      "        [-0.0884, -0.1933,  0.1859, -0.1613, -0.1750, -0.0020,  0.1784,  0.1635,\n",
      "          0.2260, -0.0482],\n",
      "        [-0.1950, -0.2476, -0.2263, -0.1369, -0.0994,  0.0869, -0.0961,  0.2209,\n",
      "         -0.1725, -0.2435],\n",
      "        [ 0.0771, -0.1067, -0.1845,  0.0072, -0.1621, -0.1780,  0.1028, -0.0653,\n",
      "         -0.0313, -0.0342]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.1898, -0.3701, -0.1372, -0.2215, -0.3269], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.2160, -0.4456,  0.1395, -0.3428,  0.3861],\n",
      "        [ 0.2520, -0.4620,  0.2262,  0.0137,  0.0375],\n",
      "        [-0.2798,  0.3698, -0.2056,  0.2559, -0.0098],\n",
      "        [ 0.6860,  2.5601, -0.4209,  0.2134, -0.3596],\n",
      "        [-0.2336, -0.3086, -0.2267, -0.3011,  0.1591]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.3921,  0.1933, -0.5300,  0.2202, -0.3216], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.2645, -0.3207,  0.4830,  2.6451,  0.0704]], requires_grad=True), Parameter containing:\n",
      "tensor([0.6689], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "param_list = list(model.parameters())\n",
    "print(param_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Trained Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.cat([input_data.cpu(),output.cpu().data],1)\n",
    "\n",
    "win_2 =viz.scatter(\n",
    "        X=data,\n",
    "        opts=dict(\n",
    "        markersize=5,\n",
    "        markercolor=np.ndarray(shape=[num_data,3],dtype=float,buffer=128*np.ones(shape=[num_data,3]))\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Loss Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.reshape([i for i in range(num_epoch)],newshape=[num_epoch,1])\n",
    "loss_data = np.reshape(loss_arr,newshape=[num_epoch,1])\n",
    "\n",
    "win3=viz.line(\n",
    "    X = x,\n",
    "    Y = loss_data,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
