{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Hyper Parameter\n",
    "train_size = 784\n",
    "num_classes = 10\n",
    "hidden1_size = 500\n",
    "learning_rate = 0.001\n",
    "\n",
    "batch_size = 100\n",
    "ephoc_size = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 9904128/9912422 [01:06<00:00, 140190.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/28881 [00:00<?, ?it/s]\u001b[A\n",
      " 57%|█████▋    | 16384/28881 [00:00<00:00, 45124.80it/s]\u001b[A\n",
      "32768it [00:00, 38003.34it/s]                           \u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1648877 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 8192/1648877 [00:01<01:26, 19075.30it/s]\u001b[A\n",
      "  1%|          | 16384/1648877 [00:01<01:07, 24322.60it/s]\u001b[A\n",
      "  2%|▏         | 40960/1648877 [00:01<00:52, 30620.69it/s]\u001b[A\n",
      "  3%|▎         | 49152/1648877 [00:01<00:49, 32054.59it/s]\u001b[A\n",
      "  4%|▍         | 65536/1648877 [00:01<00:37, 42068.82it/s]\u001b[A\n",
      "  5%|▍         | 81920/1648877 [00:02<00:34, 45051.74it/s]\u001b[A\n",
      "  6%|▌         | 98304/1648877 [00:02<00:31, 49802.19it/s]\u001b[A\n",
      "  7%|▋         | 114688/1648877 [00:02<00:28, 54596.27it/s]\u001b[A\n",
      "  7%|▋         | 122880/1648877 [00:02<00:25, 58889.24it/s]\u001b[A\n",
      "  9%|▉         | 147456/1648877 [00:02<00:20, 74226.69it/s]\u001b[A\n",
      " 10%|▉         | 163840/1648877 [00:02<00:17, 86595.61it/s]\u001b[A\n",
      " 11%|█         | 180224/1648877 [00:03<00:14, 100014.81it/s]\u001b[A\n",
      " 12%|█▏        | 196608/1648877 [00:03<00:15, 92049.25it/s] \u001b[A\n",
      " 13%|█▎        | 221184/1648877 [00:03<00:13, 107381.42it/s]\u001b[A\n",
      " 14%|█▍        | 237568/1648877 [00:03<00:12, 111914.80it/s]\u001b[A\n",
      " 16%|█▋        | 270336/1648877 [00:03<00:10, 135848.74it/s]\u001b[A\n",
      " 18%|█▊        | 294912/1648877 [00:03<00:10, 134176.58it/s]\u001b[A\n",
      " 19%|█▉        | 319488/1648877 [00:03<00:08, 148877.54it/s]\u001b[A\n",
      " 21%|██        | 344064/1648877 [00:04<00:08, 158431.90it/s]\u001b[A\n",
      " 22%|██▏       | 368640/1648877 [00:04<00:08, 157744.01it/s]\u001b[A\n",
      " 24%|██▍       | 393216/1648877 [00:04<00:08, 144257.23it/s]\u001b[A\n",
      " 26%|██▌       | 425984/1648877 [00:04<00:07, 159935.01it/s]\u001b[A\n",
      " 27%|██▋       | 450560/1648877 [00:04<00:08, 142736.04it/s]\u001b[A\n",
      " 28%|██▊       | 466944/1648877 [00:05<00:09, 125293.72it/s]\u001b[A\n",
      " 29%|██▉       | 483328/1648877 [00:05<00:09, 120743.99it/s]\u001b[A\n",
      " 30%|███       | 499712/1648877 [00:05<00:10, 106532.72it/s]\u001b[A\n",
      " 31%|███▏      | 516096/1648877 [00:05<00:10, 107320.69it/s]\u001b[A\n",
      " 32%|███▏      | 532480/1648877 [00:05<00:12, 91604.40it/s] \u001b[A\n",
      " 33%|███▎      | 548864/1648877 [00:05<00:11, 96174.16it/s]\u001b[A\n",
      " 34%|███▍      | 565248/1648877 [00:06<00:11, 92595.24it/s]\u001b[A\n",
      " 35%|███▌      | 581632/1648877 [00:06<00:12, 85764.83it/s]\u001b[A\n",
      " 37%|███▋      | 606208/1648877 [00:06<00:10, 100930.18it/s]\u001b[A\n",
      " 38%|███▊      | 622592/1648877 [00:06<00:10, 98368.71it/s] \u001b[A\n",
      " 39%|███▉      | 647168/1648877 [00:06<00:09, 106529.54it/s]\u001b[A\n",
      " 40%|████      | 663552/1648877 [00:07<00:09, 100209.93it/s]\u001b[A\n",
      " 41%|████      | 679936/1648877 [00:07<00:10, 96369.01it/s] \u001b[A\n",
      " 43%|████▎     | 704512/1648877 [00:07<00:08, 111011.75it/s]\u001b[A\n",
      " 45%|████▌     | 745472/1648877 [00:07<00:06, 138930.17it/s]\u001b[A\n",
      " 47%|████▋     | 770048/1648877 [00:07<00:07, 123221.85it/s]\u001b[A\n",
      " 48%|████▊     | 786432/1648877 [00:07<00:07, 117645.33it/s]\u001b[A\n",
      " 49%|████▊     | 802816/1648877 [00:08<00:07, 118579.19it/s]\u001b[A\n",
      " 50%|████▉     | 819200/1648877 [00:08<00:10, 82230.58it/s] \u001b[A\n",
      " 51%|█████     | 843776/1648877 [00:08<00:09, 88973.76it/s]\u001b[A\n",
      " 52%|█████▏    | 860160/1648877 [00:08<00:08, 98030.09it/s]\u001b[A\n",
      " 54%|█████▎    | 884736/1648877 [00:08<00:06, 118188.52it/s]\u001b[A\n",
      " 55%|█████▌    | 909312/1648877 [00:08<00:05, 127678.43it/s]\u001b[A\n",
      " 56%|█████▌    | 925696/1648877 [00:09<00:07, 96312.83it/s] \u001b[A\n",
      " 57%|█████▋    | 942080/1648877 [00:09<00:09, 72240.04it/s]\u001b[A\n",
      " 59%|█████▊    | 966656/1648877 [00:09<00:07, 90919.39it/s]\u001b[A\n",
      " 60%|█████▉    | 983040/1648877 [00:09<00:06, 103484.68it/s]\u001b[A\n",
      " 61%|██████    | 1007616/1648877 [00:09<00:05, 123039.50it/s]\u001b[A\n",
      " 64%|██████▎   | 1048576/1648877 [00:10<00:05, 103679.90it/s]\u001b[A\n",
      " 66%|██████▌   | 1081344/1648877 [00:10<00:04, 126875.08it/s]\u001b[A\n",
      " 67%|██████▋   | 1105920/1648877 [00:10<00:03, 148252.07it/s]\u001b[A\n",
      " 69%|██████▊   | 1130496/1648877 [00:10<00:04, 120086.90it/s]\u001b[A\n",
      " 70%|██████▉   | 1146880/1648877 [00:11<00:05, 95467.62it/s] \u001b[A\n",
      "9920512it [01:20, 140190.63it/s]                             [A\n",
      " 75%|███████▍  | 1228800/1648877 [00:14<00:11, 37931.04it/s]\u001b[A\n",
      " 78%|███████▊  | 1294336/1648877 [00:14<00:06, 51882.38it/s]\u001b[A\n",
      " 80%|███████▉  | 1318912/1648877 [00:14<00:05, 59313.82it/s]\u001b[A\n",
      " 81%|████████  | 1335296/1648877 [00:15<00:04, 72091.79it/s]\u001b[A\n",
      " 83%|████████▎ | 1368064/1648877 [00:15<00:03, 89566.69it/s]\u001b[A\n",
      " 84%|████████▍ | 1384448/1648877 [00:15<00:02, 96085.56it/s]\u001b[A\n",
      " 85%|████████▌ | 1409024/1648877 [00:15<00:02, 113111.90it/s]\u001b[A\n",
      " 86%|████████▋ | 1425408/1648877 [00:15<00:02, 110226.81it/s]\u001b[A\n",
      " 88%|████████▊ | 1449984/1648877 [00:15<00:01, 119433.55it/s]\u001b[A\n",
      " 90%|████████▉ | 1482752/1648877 [00:15<00:01, 147445.32it/s]\u001b[A\n",
      " 91%|█████████▏| 1507328/1648877 [00:16<00:00, 154870.19it/s]\u001b[A\n",
      " 93%|█████████▎| 1531904/1648877 [00:16<00:00, 162339.21it/s]\u001b[A\n",
      " 94%|█████████▍| 1556480/1648877 [00:16<00:00, 171521.53it/s]\u001b[A\n",
      " 96%|█████████▌| 1581056/1648877 [00:16<00:00, 188290.05it/s]\u001b[A\n",
      " 97%|█████████▋| 1605632/1648877 [00:16<00:00, 193686.18it/s]\u001b[A\n",
      " 99%|█████████▉| 1630208/1648877 [00:16<00:00, 163567.71it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/4542 [00:01<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "8192it [00:01, 5339.75it/s]             \u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# 2. Data load\n",
    "# MNIST Dataset \n",
    "train_dataset = dsets.MNIST(root='./data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),  \n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Build the Model\n",
    "class FeedForwardNN(nn.Module):\n",
    "    def __init__(self, train_size, hidden1_size, num_classes):\n",
    "        super(FeedForwardNN, self).__init__()\n",
    "        self.linear1 = nn.Linear(train_size, hidden1_size) #784x20\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden1_size, num_classes) #20x10\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z1 = self.linear1(x)\n",
    "        a1 = self.relu(z1)\n",
    "        z2 = self.linear2(a1)\n",
    "        \n",
    "        return z2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Generate a model\n",
    "model = FeedForwardNN(train_size, hidden1_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Init loss function and Optimizer\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ephoc:  0\n",
      "ephoc[ 0 ] \t loss: 2.2076711654663086\n",
      "ephoc[ 0 ] \t loss: 0.23751743137836456\n",
      "ephoc[ 0 ] \t loss: 0.24504905939102173\n",
      "ephoc[ 0 ] \t loss: 0.2440721094608307\n",
      "ephoc[ 0 ] \t loss: 0.14754512906074524\n",
      "ephoc[ 0 ] \t loss: 0.12520276010036469\n",
      "ephoc:  1\n",
      "ephoc[ 1 ] \t loss: 0.16524162888526917\n",
      "ephoc[ 1 ] \t loss: 0.10681936144828796\n",
      "ephoc[ 1 ] \t loss: 0.055490948259830475\n",
      "ephoc[ 1 ] \t loss: 0.11570068448781967\n",
      "ephoc[ 1 ] \t loss: 0.07411623001098633\n",
      "ephoc[ 1 ] \t loss: 0.052554111927747726\n",
      "ephoc:  2\n",
      "ephoc[ 2 ] \t loss: 0.08383353054523468\n",
      "ephoc[ 2 ] \t loss: 0.03309843689203262\n",
      "ephoc[ 2 ] \t loss: 0.04478994011878967\n",
      "ephoc[ 2 ] \t loss: 0.08570170402526855\n",
      "ephoc[ 2 ] \t loss: 0.014440944418311119\n",
      "ephoc[ 2 ] \t loss: 0.02342766337096691\n",
      "ephoc:  3\n",
      "ephoc[ 3 ] \t loss: 0.011843901127576828\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-a09fdd59c0f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mephoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mephoc_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ephoc: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mephoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;31m#convert dataset as the Pytorch style\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/NLPApps/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/NLPApps/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/NLPApps/lib/python3.7/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/NLPApps/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \"\"\"\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/NLPApps/lib/python3.7/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m255\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteStorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0;31m# PIL image mode: L, LA, P, I, F, RGB, YCbCr, RGBA, CMYK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'YCbCr'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 6. Train\n",
    "for ephoc in range(ephoc_size):\n",
    "    print(\"ephoc: \",ephoc)\n",
    "    for idx, (images, labels) in enumerate(train_loader):\n",
    "        #convert dataset as the Pytorch style\n",
    "        images = Variable(images.view(-1,28*28))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        #Forward, Backward, gradient\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if idx%100 == 0:\n",
    "            print(\"ephoc[\",ephoc,\"] \\t\", \"loss:\", loss.item())\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 97 %\n"
     ]
    }
   ],
   "source": [
    "#Test the model\n",
    "total = 0\n",
    "correct = 0\n",
    "for images, labels in test_loader:\n",
    "    images = Variable(images.view(-1,28*28))\n",
    "\n",
    "    outputs = model(images)   \n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += len(predicted)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
