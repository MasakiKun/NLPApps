{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/5], Step: [100/600], Loss: 0.7732\n",
      "Epoch: [1/5], Step: [200/600], Loss: 0.5392\n",
      "Epoch: [1/5], Step: [300/600], Loss: 0.4369\n",
      "Epoch: [1/5], Step: [400/600], Loss: 0.5564\n",
      "Epoch: [1/5], Step: [500/600], Loss: 0.3297\n",
      "Epoch: [1/5], Step: [600/600], Loss: 0.3948\n",
      "Epoch: [2/5], Step: [100/600], Loss: 0.4115\n",
      "Epoch: [2/5], Step: [200/600], Loss: 0.4573\n",
      "Epoch: [2/5], Step: [300/600], Loss: 0.3628\n",
      "Epoch: [2/5], Step: [400/600], Loss: 0.2315\n",
      "Epoch: [2/5], Step: [500/600], Loss: 0.2216\n",
      "Epoch: [2/5], Step: [600/600], Loss: 0.3668\n",
      "Epoch: [3/5], Step: [100/600], Loss: 0.1982\n",
      "Epoch: [3/5], Step: [200/600], Loss: 0.3884\n",
      "Epoch: [3/5], Step: [300/600], Loss: 0.2630\n",
      "Epoch: [3/5], Step: [400/600], Loss: 0.2626\n",
      "Epoch: [3/5], Step: [500/600], Loss: 0.3385\n",
      "Epoch: [3/5], Step: [600/600], Loss: 0.2953\n",
      "Epoch: [4/5], Step: [100/600], Loss: 0.2854\n",
      "Epoch: [4/5], Step: [200/600], Loss: 0.3283\n",
      "Epoch: [4/5], Step: [300/600], Loss: 0.1881\n",
      "Epoch: [4/5], Step: [400/600], Loss: 0.3643\n",
      "Epoch: [4/5], Step: [500/600], Loss: 0.3047\n",
      "Epoch: [4/5], Step: [600/600], Loss: 0.1783\n",
      "Epoch: [5/5], Step: [100/600], Loss: 0.3361\n",
      "Epoch: [5/5], Step: [200/600], Loss: 0.3389\n",
      "Epoch: [5/5], Step: [300/600], Loss: 0.2955\n",
      "Epoch: [5/5], Step: [400/600], Loss: 0.2355\n",
      "Epoch: [5/5], Step: [500/600], Loss: 0.3014\n",
      "Epoch: [5/5], Step: [600/600], Loss: 0.1306\n",
      "Total number:  10000 Correct answer:  tensor(9236) ratio:  tensor(0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 1. Hyper parameters\n",
    "train_size = 784\n",
    "test_size = 10\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "ephoc_size = 5\n",
    "\n",
    "# 2. Preparing datasets\n",
    "    # MNIST Dataset (Images and Labels)\n",
    "train_dataset = dsets.MNIST(root='./data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "    # Dataset Loader (Input Pipline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n",
    "#print(train_dataset[0])\n",
    "\n",
    "# 3. Build a Module(a Model)\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, train_size, test_size):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.logistic = nn.Linear(train_size, test_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #x_train = torch.FloatTensor(x)\n",
    "        out = self.logistic(x)\n",
    "        #out_sigm = nn.Softmax(x_train)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "\n",
    "# 4. model generation\n",
    "model = LogisticRegressionModel(train_size, test_size)\n",
    "    \n",
    "# 5. Define Loss and Optimizer funtion\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 6. Train the model with batch_size\n",
    "for ephoc in range(ephoc_size):\n",
    "    for idx, (images, labels) in enumerate(train_loader): #Forward, Backward, Loss and Optimizer for each data\n",
    "        #convert data type to fit for Pytorch and vectorization\n",
    "        input_images = images.view(-1,28*28) # Convert from 100x28x28 to 100x784\n",
    "        answer_labels = labels\n",
    "        \n",
    "        optimizer.zero_grad() #init grads\n",
    "        a_prediction = model(input_images) # Forward\n",
    "        loss = loss_func(a_prediction, answer_labels) #Loss\n",
    "        loss.backward()\n",
    "        optimizer.step() #Backward\n",
    "        \n",
    "        #print(loss)\n",
    "    \n",
    "        if (idx+1) % 100 == 0:\n",
    "            print('Epoch: [%d/%d], Step: [%d/%d], Loss: %.4f' \n",
    "                   % (ephoc+1, ephoc_size, idx+1, len(train_dataset)//batch_size, loss.item()))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number:  10000 Correct answer:  9236 ratio:  92.36\n"
     ]
    }
   ],
   "source": [
    "# 7. Test the model\n",
    "total = 0\n",
    "correct = 0\n",
    "for idx, (images, labels) in enumerate(test_loader):\n",
    "    #preparing test dataset\n",
    "    test_images = images.view(-1, 28*28)\n",
    "    test_labels = labels\n",
    "    \n",
    "    #predict models\n",
    "    output = model(test_images)\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    total += len(predicted)\n",
    "    correct += (predicted == labels).sum()\n",
    "    \n",
    "    \n",
    "print(\"Total number: \", total, \"Correct answer: \", correct.item(), \"ratio: \",correct.item()/total * 100)\n",
    "\n",
    "torch.save(model.state_dict(), 'model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
